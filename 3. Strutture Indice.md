Lo scopo delle strutture indice in un IRS è quello di incrementare l'efficienza del sistema. Le strutture a indice consento questo andando a:
1. velocizzare le operazioni di ricerca;
2. ottimizzare l'accesso alle informazioni dei termini della collezione;
3. ottimizzare le ricerche dei singoli termini.

La tabella delle occorrenze come prodotta nel formato documento/termine descritto durante le lezioni precedenti è fortemente sparsa, questo perché molte delle celle della matrice vengono lasciate vuote al fine di indicare la non occorrenza di un termine all'interno di un particolare documento. Il risultato di questa scelta è che la memorizzazione della matrice in memoria richiede una quantità di spazio molto maggiore. Un altro effetto indesiderato di questa soluzione è che ottenere l'elenco dei documenti che contengono uno specifico termine risulta particolarmente costoso.

Per far fronte ai problemi presentati si adotta una soluzione differente rispetto a quella proposta, la tabella delle occorrenze viene invertita, ad ogni termine si associano i documenti in cui questo è contenuto. Questo rende pià veloce l'accesso all'elenco dei documenti contenenti uno specifico termine, una delle operazioni fondamentali per un IRS.

Questo struttura dati è nota con il nome di struttura a File Inverted e viene utilizzata indipendentemente dal modello di retrieval che il sistema di IR adotta. In una struttura dati a File Inverted i termini indice della collezione vengono mantenuti all'interno di un file detto dizionario. Nel dizionario di una collezione, ogni termine viene memorizzato insieme alla sua frequenza globale, ossia al suo numero di occorrenze all'interno della collezione; questo sia al fine di poter calcolare l'IDF e sia al fine di ottimizzare la valutazione di query booleane. Ad ognuno dei termini presenti nel dizionario viene associata la lista dei documenti in cui questo è contenuto, lista che verrà memorizzata all'interno del cosiddetto posting file. Per ogni documento puntato viene indicato l'identificatore univoco del documento, denotato con DocID, e vengono memorizzate la frequenza del termine nel documento, denotata come $tf$ e la posizione di ogni occorrenza del termine. Questa seconda informazione è opzionale, in quanto utile solamente per query con contesto, e può essere espressa in termini di numero di parole o byte dall'inizio del documento, oppure indicando il numero di sezione, paragrafo, frase e parola a cui il termine è presente all'interno del documento. Questo consente la valutazione di operatori di adiacenza e di vicinanza e la progettazione di interfacce utente per l'evidenziazione delle occorrenze dei termini cercati all'interno dei documenti reperiti per una query.

In termini di occupazione di memoria, lo spazio richiesto per memorizzare il dizione è piuttosto ridotto. Mentre il vocabolario viene memorizzato in maniera piuttosto efficiente e cresce secondo la legge di Heap, ossia come $O(n^B)$, dove $n$ è lo spazio occupato dal testo dei documenti $B$ è una costante tra 0.4 e 0.6, le occorrenze richiedono molto più spazio. Questo perché ogni parola che compare nel testo è riferita una volta nella struttura dati e quindi lo spazio cresce come $O(n)$.

Ai fini di ottimizzare il posting file si applicano tecniche di ottimizzazione alle diverse componenti di questo: i nomi dei termini, gli identificatori dei documenti, il conteggio delle occorrenze dei termini e la posizione di questi all'interno del documento. Le principali tecniche di ottimizzazione utilizzate sono:
- compressione dei DocID indirizzo relativo, in cui la lista dei DocID viene ordinata per poter poi sostituire, a ogni DocID, la distanza dal DocID che lo precede; si tratta di una tecnica molto semplice ma che porta ad una riduzione delle dimensioni dell'indice del 10-15%;
- compressione divisione a blocchi del testo del documento, in cui il testo di ogni documento viene diviso in blocchi e, piuttosto che memorizzare l'offset dall'inizio del documento, viene memorizzato il blocco all'interno del quale compare il termine in analisi. La riduzione dell'occupazione di memoria prodotta dall'utilizzo di questa tecnica è legata sia al fatto che la dimensione del puntatore al blocco è minore rispetto a quella dell'offset rispetto all'inizio del documento, sia al fatto che tutte le occorrenze di una parola contenute all'interno di un singolo blocco utilizzeranno lo stesso riferimento. Lo principale svantaggio causato da questa tecnica è rappresentato dal fatto che le ricerche per contesto richiederanno più operazioni.

In un IRS che adotta una struttura a File Inverted, a fronte di una ricerca devono essere eseguite le seguenti operazioni:
- accesso al file dizionario e ricerca dei termini nella query;
- reperimento della lista di posting associata ad ognuno dei termini trovati all'interno del dizionario;
- filtraggio dei risultati, questo perché, se la query contiene più termini connessi da operatori, le liste parziali dei risultati andranno fuse in un'unica lista globale.

Inoltre, se gli operatori utilizzati dalla query sono di prossimità o adiacenza e il File Inverted adotta un indirizzamento a blocchi, risulta necessario scandire ognuno dei blocchi contenenti i termini della query in maniera tale da ottenere gli offset delle occorrenze dei termini.

Nel caso invece di File Inverted che utilizzano un indirizzamento lineare, l'indice può essere acceduto molto velocemente (ad esempio, con ricerca binaria in $O(log n)$), portando a miglioramenti rispetto alle performance di valutazioni sequenziali. Un altro significativo vantaggio è rappresentato dal risparmio ottenuto da questa strategia di indirizzamento in termini di occupazione di memoria. Il problema fondamentale di questa tecnica si evidenzia nel caso di collezioni il cui contenuto può cambiare (possono essere aggiunti o tolti documenti), in caso di modifica del contenuto infatti gli indici costruiti utilizzando un indirizzamento verranno invalidati e dovranno essere ricostruiti.

Un'altra strategia di indirizzamento per gli indici contenuti in un File Inverted è quella basata su B-Tree. Un indice a B-Tree di ordine $d$ utilizza una struttura ad albero bilanciato, in cui la radice contiene da $1$ a $d$ termini e ogni altro nodo contiene da $d/2$ termini a $d$ termini. L'idea alla base del funzionamento di questo tipo di struttura è la seguente: se $k_i$ è l'$i$-esimo termine in un nodo intermedio:
- tutti i termini nell'$i-1$-esimo figlio sono lessicograficamente minori di $k_i$;
- tutti i termini nell'$i$-esimo figlio sono lessicograficamente maggiori di $k_i$.
Questa strategia porta dei significativi miglioramenti rispetto ai problemi segnalati per le strategie precedenti, strutture di questo tipo possono infatti essere accedute molto velocemente ($O(log_d n)$, dove $d$ e $n$ sono ordine e profondità dell'albero). Oltre ai vantaggi in termini di tempo, anche dal punto di vista dello spazio si evidenziano dei miglioramenti. In alcuni contesti questa strategia può risultare inadatta, in particolare:
- molte ricerche sequenziali, le ricerche sequenziali in questo contesto risultano infatti particolarmente inefficienti;
- indice memorizzato su disco, questo perché ogni nodo può richiedere un accesso al disco separato;
- molte operazioni di inserimento, questo perché nel caso peggiore l'albero risultante potrebbe essere fortemente sbilanciato.

La strategia di indirizzamento a Suffix-Tree tratta il documento come se fosse un unica stringa e definisce un lavora basandosi su tutti i diversi suffissi presenti all'interno di questo, identificando ogni suffisso con il suo indice iniziale. Dal testo vengono selezionati dei punti indice che possono essere reperiti e i puntatori ai suffissi vengono memorizzati nelle foglie dell'albero prodotto, in maniera tale da memorizzare una sola volta le parti comuni tra i diversi suffissi. Questa strategia particolarmente adatta a ricerche complesse, sia ricerche di intere frasi che ricerche sequenziali di termini o prefissi. Gli svantaggi legati all'utilizzo di questa tecnica sono rappresentati da:
- costo elevato del processo di creazione dell'indice;
- incremento della dimensione dell'indice (120-240% rispetto alla dimensione della collezione).

L'ultima strategia di indirizzamento che analizziamo è quella a Signature. Una strategia di indirizzamento a Signature definisce una funzione $h(x)$ che mappa gli indici, ossia le $x$, in maschere di $B$ bit dette signature, dividendo quindi il testo in blocchi di $b$ indici e associando ad unono una maschera di bit ottenuta tramite OR delle signature degli indici del blocco. L'indice signature di un documento sarà quindi costituito da una sequenza di maschere di bit, una per blocco, e un puntatore ad ognuno dei blocchi. In fase di ricerca si confronta la stringa di b associata dalla funzione $h$ al termine ricercato verificando se questa è inclusa nella signature di un documento. Il problema di questo meccanismo di funzionamento è che può dare origine a falsi risultati. Un false drop rappresentato dalla probabilità che una signature di un blocco soddisfi una query anche se il blocco non contiene il termine ricercato, cosa che avviene molto spesso in presenza di molti 1 nella signature di un documento. La scelta di indicizzare a blocchi i documenti è legata a questo problema, si osserva infatti che i false drop si minimizzando andando a considerare parti di documento più piccole e la cui firma conterrà quindi probabilmente un numero ridotto di 1. L'applicazione di questo tipo di tecnica di indicizzazione è prevalente nel contesto di dati multimediali. Oltre che per collezioni di dati multimediali questa tecnica risulta particolarmente appropriata per testi non troppo grossi grazie alla ridotta occupazione di memoria che la contraddistingue (10-20% rispetto alla dimensione della collezione). Gli svantaggi di questa tecnica sono rappresentati dall'eventualità di false drop, come detto in precedenza, e dalla problematicità delle ricerche sequenziali.
